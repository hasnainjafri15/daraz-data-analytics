{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "os.chdir(\"./\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"./sales_data\" # use your path\n",
    "#all_files = glob.glob(\"./sales_data\" + \"/*.csv\")\n",
    "\n",
    "##li = []\n",
    "\n",
    "##for filename in all_files:\n",
    "   # df = pd.read_csv(filename, index_col=None, header=0)\n",
    "   # li.append(df)\n",
    "\n",
    "#all_data = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "#all_data.to_csv(\"all data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create seperate dataframes for different clusters\n",
    "# create seperate dataframes for different Level 1 assortments\n",
    "# do cluster wise and Level 1 wise analysis\n",
    "# which cluster are doing the best and worst\n",
    "# which assortments are doing the best and the worst\n",
    "\n",
    "# can we combine dataframes from multiple days and run the same analysis on that\n",
    "\n",
    "# what key metrics can we create and analyse data based on data metrice\n",
    "# A2C/Search   .... order/A2C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key obstacles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create seperate dataframes for each LV1 assortment and perform a deeper analysis\n",
    "# create seperate dataframes for each cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDP = product display page\n",
    "# GMV = Gross merchandise value\n",
    "# ASP = average selling price\n",
    "# ARPU = Average revenue per unit = GMV/orders\n",
    "# found items = products found through keyword\n",
    "# E.items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"keywords report 12 Dec.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 12'], axis=1)\n",
    "df = df.drop(['Unnamed: 13'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(['Furniture & Décor'], 'Furniture & Decor')\n",
    "df = df.replace(['TV Audio Video Gaming & Wearables'],\n",
    "                'TV, Audio / Video, Gaming & Wearables')\n",
    "df = df.replace(['Tools DIY & Outdoor'], 'Tools, DIY & Outdoor')\n",
    "\n",
    "# furniture and decor #Furniture & Décor\n",
    "# TV Audio Video Gaming & Wearables #TV, Audio / Video, Gaming & Wearables\n",
    "# Tools DIY & Outdoor #Tools, DIY & Outdoor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new metrics columns\n",
    "\n",
    "df[\"PDP % of searches\"] = df['PDP UV']/df[\"Search UV\"]*100\n",
    "df[\"A2C % of searches\"] = df['A2C_UV']/df[\"Search UV\"]*100\n",
    "df[\"ORDER % of searches\"] = df['Order_UV']/df[\"Search UV\"]*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing percentages to 2 decimal places\n",
    "\n",
    "df[\"PDP % of searches\"] = df['PDP % of searches']. round(decimals=2)\n",
    "df[\"A2C % of searches\"] = df['A2C % of searches']. round(decimals=2)\n",
    "df[\"ORDER % of searches\"] = df['ORDER % of searches']. round(decimals=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding out LV1 assortments within each cluster\n",
    "# i think this is an ineffective way to do this. This works but this could be better\n",
    "\n",
    "\n",
    "df['Category'] = df[\"LV1\"] + \" \" + df[\"Cluster\"]\n",
    "data = dict(zip(df.LV1, df.Cluster))\n",
    "sp = pd.DataFrame.from_dict(data, orient=\"index\")\n",
    "sp = sp.rename(columns={0: \"Cluster\"}, inplace=False)\n",
    "sp = sp.rename(columns={\"\": \"Cluster\"}, inplace=False)\n",
    "sp.sort_values(by=\"Cluster\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_sort = df.sort_values(by=[\"Search UV\"], ascending=False)\n",
    "kw_sort.head()\n",
    "# keywords ranked by number of unique searches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Cluster'].nunique())\n",
    "print(df['LV1'].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_df = df.groupby('Cluster').sum()\n",
    "cl_df.sort_values(by=['Search UV'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have sorted data based on the clusters\n",
    "# I then grouped all the data for a particular LV1 assortment within a cluster\n",
    "# I then sorted the data in aesc order\n",
    "\n",
    "EL = df.loc[df[\"Cluster\"] == \"EL\"]\n",
    "Fashion = df.loc[df[\"Cluster\"] == \"Fashion\"]\n",
    "FMCG = df.loc[df[\"Cluster\"] == \"FMCG\"]\n",
    "GM = df.loc[df[\"Cluster\"] == \"GM\"]\n",
    "Digital_Goods = df.loc[df[\"Cluster\"] == \"Digital Goods\"]\n",
    "Others = df.loc[df[\"Cluster\"] == \"Others\"]\n",
    "\n",
    "EL = EL.groupby('LV1').sum().sort_values(by=\"Search UV\", ascending=False)\n",
    "Fashion = Fashion.groupby('LV1').sum().sort_values(\n",
    "    by=\"Search UV\", ascending=False)\n",
    "FMCG = FMCG.groupby('LV1').sum().sort_values(by=\"Search UV\", ascending=False)\n",
    "GM = GM.groupby('LV1').sum().sort_values(by=\"Search UV\", ascending=False)\n",
    "Digital_Goods = Digital_Goods.groupby(\n",
    "    'LV1').sum().sort_values(by=\"Search UV\", ascending=False)\n",
    "Others = Others.groupby('LV1').sum().sort_values(\n",
    "    by=\"Search UV\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FMCG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 1 assortment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv = df.groupby(\"LV1\").sum()\n",
    "lv = lv.sort_values(by=['Search UV'], ascending=False)\n",
    "print(lv.shape)\n",
    "lv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.sort_values(by=\"A2C % of searches\", ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing dataframe into CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv.to_csv(\"Level 1 assortment data.csv\")\n",
    "cl_df.to_csv(\"Cluster analysis.csv\")\n",
    "kw_sort.to_csv(\"Keyword analysis.csv\")\n",
    "EL.to_csv(\"EL cluster analysis.csv\")\n",
    "FMCG.to_csv(\"FMCG Cluster analysis.csv\")\n",
    "Fashion.to_csv(\"Fashion Cluster analysis.csv\")\n",
    "GM.to_csv(\"GM cluster analysis.csv\")\n",
    "Digital_Goods.to_csv(\"digital goods cluster analysis.csv\")\n",
    "Others.to_csv(\"others cluster analysis.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
